{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from preprocessing import *\n",
    "from defaultlist import defaultlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = './Friends/'\n",
    "files_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for file in files:\n",
    "        files_list.append(os.path.abspath(os.path.join(root, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepro_files = defaultlist()\n",
    "files_length = defaultlist()\n",
    "\n",
    "for file in files_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        lemmas_list = preprocessing(f.read())\n",
    "        prepro_files[files_list.index(file)] = lemmas_list\n",
    "        files_length[files_list.index(file)] = len(lemmas_list)\n",
    "        # print(files_list[files_list.index(file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('files_list.json', 'w', encoding='utf-8') as fw:\n",
    "    json.dump(files_list, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lemmad.json', 'w', encoding='utf-8') as fw:\n",
    "    json.dump(prepro_files, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# матрица терм-документ:\n",
    "# словарь, где ключи -- леммы, а значения -- список частотностей в коллекции документов\n",
    "\n",
    "def get_term_doc_matrix(prepro_files):\n",
    "    \n",
    "    term_doc_matrix = defaultdict(list)\n",
    "    n = len(prepro_files)\n",
    "    \n",
    "    for indx, lemmas in enumerate(prepro_files):\n",
    "        for lemma in lemmas:\n",
    "            if lemma in term_doc_matrix:\n",
    "                term_doc_matrix[lemma][indx] += 1\n",
    "            else:\n",
    "                term_doc_matrix[lemma] = [0] * len(prepro_files)\n",
    "                term_doc_matrix[lemma][indx] += 1\n",
    "\n",
    "    return term_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обратный индекс:\n",
    "# словарь, где ключи -- леммы, а значения -- список документов, где встретилась эта лемма\n",
    "\n",
    "def inverted_index(prepro_files) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    \n",
    "    term_doc_matrix = get_term_doc_matrix(prepro_files)\n",
    "    inverted_index = defaultdict(list)\n",
    "    \n",
    "    for lemma in term_doc_matrix:\n",
    "        for indx, doc in enumerate(term_doc_matrix[lemma]):\n",
    "            if doc > 0:\n",
    "                inverted_index[lemma].append(indx)\n",
    "\n",
    "    return inverted_index, term_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_index, term_doc_matrix = inverted_index(prepro_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_BM25(qf, dl, avgdl, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    k1 = 2.0\n",
    "    b = 0.75\n",
    "\n",
    "    score = log((N - n + 0.5) / (n + 0.5)) * (k1 + 1) * qf / (qf + k1 * (1 - b + b * (dl / avgdl)))\n",
    "    \n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sim(lemma, inverted_index, term_doc_matrix, files_length) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    \n",
    "    relevance_score = {}\n",
    "    avgdl = sum(files_length) / len(files_length)\n",
    "    N = len(files_length)\n",
    "\n",
    "    for doc in range(N):\n",
    "        if lemma in term_doc_matrix:\n",
    "            qf = term_doc_matrix[lemma][doc]\n",
    "            n = len(inverted_index[lemma])\n",
    "        else:\n",
    "            qf = 0\n",
    "            n = 0\n",
    "\n",
    "        relevance_score[doc] = score_BM25(qf, files_length[doc], avgdl, N, n)\n",
    "\n",
    "    return relevance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('inverted_index.json', 'w', encoding='utf-8') as fw:\n",
    "    json.dump(inverted_index, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('term_doc_matrix.json', 'w', encoding='utf-8') as fw:\n",
    "    json.dump(term_doc_matrix, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('files_length.json', 'w', encoding='utf-8') as fw:\n",
    "    json.dump(files_length, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_inv_index(query, inverted_index, term_doc_matrix, files_length, n_results) -> list:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    \n",
    "    relevance_dict = defaultdict(float)\n",
    "    lemmas = preprocessing(query)\n",
    "    \n",
    "    for lemma in lemmas:\n",
    "        sims = compute_sim(lemma, inverted_index, term_doc_matrix, files_length)\n",
    "        for doc in sims:\n",
    "            relevance_dict[doc] += sims[doc]\n",
    "            \n",
    "    result = sorted(relevance_dict, key=relevance_dict.get, reverse=True)[:n_results]\n",
    "\n",
    "    return [(files_list[doc].split('/Friends/Friends - ')[1].strip('.ru.txt'),\n",
    "                                         relevance_dict[doc]) for doc in result] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_matrix['ходить']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {0: 0.0, 1: 0.0, 2: -0.06450907055724057, 3: -0.06083843040843744, 4: 0.0, 5: -0.05469781192451975, 6: 0.0, 7: 0.0, 8: 0.0, 9: -0.08979895728075477, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: -0.06074501254551583, 17: 0.0, 18: -0.060343495039614295, 19: -0.06270271578105113, 20: 0.0, 21: 0.0, 22: 0.0, 23: -0.10773631893792934, 24: 0.0, 25: 0.0, 26: 0.0, 27: -0.07725970396196148, 28: 0.0, 29: -0.05988675138700505, 30: 0.0, 31: 0.0, 32: -0.08862544452376406, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: -0.06046647238967371, 39: 0.0, 40: -0.09024278783825525, 41: -0.05958607757839268, 42: -0.059556176169649366, 43: 0.0, 44: -0.06105752683590743, 45: -0.14593360265834607, 46: 0.0, 47: -0.08787083709443606, 48: -0.09451909682939202, 49: -0.09296429485521526, 50: 0.0, 51: -0.06290211474358813, 52: -0.059407118151878, 53: 0.0, 54: 0.0, 55: -0.05931804094608508, 56: -0.06276904148834643, 57: -0.09355053083404649, 58: -0.06182084470933862, 59: 0.0, 60: -0.09156566279138875, 61: 0.0, 62: -0.09289153156161786, 63: -0.05911122935436714, 64: 0.0, 65: -0.06454415363944373, 66: -0.0551297534636023, 67: -0.061853064016644005, 68: 0.0, 69: 0.0, 70: -0.09058719276475963, 71: -0.0602210168995227, 72: 0.0, 73: 0.0, 74: 0.0, 75: -0.06037419245715384, 76: 0.0, 77: -0.05695528446445773, 78: 0.0, 79: 0.0, 80: -0.12023607792494662, 81: -0.06143681491529243, 82: -0.062047087328694794, 83: -0.09024278783825525, 84: 0.0, 85: 0.0, 86: -0.05826958242860108, 87: -0.11082144241012212, 88: -0.06323727959751664, 89: 0.0, 90: 0.0, 91: -0.0579000232083871, 92: 0.0, 93: -0.06037419245715384, 94: -0.09089941256234661, 95: 0.0, 96: -0.09031145916033803, 97: -0.0605281492231964, 98: 0.0, 99: -0.10393099714318904, 100: -0.08506804256934303, 101: -0.05767492305306878, 102: -0.087643718000509, 103: -0.059705984069972136, 104: 0.0, 105: 0.0, 106: 0.0, 107: -0.11643193622140503, 108: -0.08589925040445116, 109: -0.09041466232836658, 110: -0.05928840787699679, 111: -0.10882298347012416, 112: 0.0, 113: 0.0, 114: -0.12215428393645603, 115: -0.06083843040843744, 116: 0.0, 117: 0.0, 118: -0.06500373096436965, 119: -0.09577769746172755, 120: -0.10993179228046238, 121: 0.0, 122: -0.05878913744854423, 123: -0.10744371212209447, 124: 0.0, 125: -0.09202717387052263, 126: -0.06670727243580146, 127: -0.09145981683393326, 128: -0.06006861661933132, 129: -0.061500488206317636, 130: -0.13724918048691043, 131: -0.06306925188745943, 132: -0.06182084470933862, 133: 0.0, 134: -0.14228448626471774, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: -0.061500488206317636, 142: -0.05747939131067321, 143: -0.09224175173950536, 144: 0.0, 145: 0.0, 146: 0.0, 147: -0.05946665173379024, 148: 0.0, 149: -0.05855708477900265, 150: 0.0, 151: -0.0884273436885632, 152: 0.0, 153: -0.09497292418396802, 154: 0.0, 155: -0.055988005882008446, 156: 0.0, 157: 0.0, 158: -0.06290211474358813, 159: 0.0, 160: -0.058041605260727804, 161: 0.0, 162: -0.05826958242860108, 163: 0.0, 164: 0.0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('season 7/Friends - 7x06 - The One With The Nap Partners', 0.0),\n",
       " (\"season 7/Friends - 7x19 - The One With Ross And Monica's Cousin\", 0.0),\n",
       " (\"season 7/Friends - 7x18 - The One With Joey's Award\", 0.0),\n",
       " ('season 7/Friends - 7x10 - The One With The Holiday Armadillo', 0.0),\n",
       " ('season 7/Friends - 7x13 - The One Where Rosita Dies', 0.0),\n",
       " ('season 7/Friends - 7x09 - The One With All The Candy', 0.0),\n",
       " (\"season 7/Friends - 7x15 - The One With Joey's New Brain\", 0.0),\n",
       " (\"season 7/Friends - 7x02 - The One With Rachel's Book\", 0.0),\n",
       " (\"season 7/Friends - 7x24-25 - The One With Chandler And Monica's Wedding (2)\",\n",
       "  0.0),\n",
       " (\"season 7/Friends - 7x12 - The One Where They're Up All Nigh\", 0.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_inv_index('ходить', inverted_index, term_doc_matrix, files_length, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {0: 0.0, 1: 0.0, 2: -0.06450907055724057, 3: -0.06083843040843744, 4: 0.0, 5: -0.05469781192451975, 6: 0.0, 7: 0.0, 8: 0.0, 9: -0.08979895728075477, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: -0.06074501254551583, 17: 0.0, 18: -0.060343495039614295, 19: -0.06270271578105113, 20: 0.0, 21: 0.0, 22: 0.0, 23: -0.10773631893792934, 24: 0.0, 25: 0.0, 26: 0.0, 27: -0.07725970396196148, 28: 0.0, 29: -0.05988675138700505, 30: 0.0, 31: 0.0, 32: -0.08862544452376406, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: -0.06046647238967371, 39: 0.0, 40: -0.09024278783825525, 41: -0.05958607757839268, 42: -0.059556176169649366, 43: 0.0, 44: -0.06105752683590743, 45: -0.14593360265834607, 46: 0.0, 47: -0.08787083709443606, 48: -0.09451909682939202, 49: -0.09296429485521526, 50: 0.0, 51: -0.06290211474358813, 52: -0.059407118151878, 53: 0.0, 54: 0.0, 55: -0.05931804094608508, 56: -0.06276904148834643, 57: -0.09355053083404649, 58: -0.06182084470933862, 59: 0.0, 60: -0.09156566279138875, 61: 0.0, 62: -0.09289153156161786, 63: -0.05911122935436714, 64: 0.0, 65: -0.06454415363944373, 66: -0.0551297534636023, 67: -0.061853064016644005, 68: 0.0, 69: 0.0, 70: -0.09058719276475963, 71: -0.0602210168995227, 72: 0.0, 73: 0.0, 74: 0.0, 75: -0.06037419245715384, 76: 0.0, 77: -0.05695528446445773, 78: 0.0, 79: 0.0, 80: -0.12023607792494662, 81: -0.06143681491529243, 82: -0.062047087328694794, 83: -0.09024278783825525, 84: 0.0, 85: 0.0, 86: -0.05826958242860108, 87: -0.11082144241012212, 88: -0.06323727959751664, 89: 0.0, 90: 0.0, 91: -0.0579000232083871, 92: 0.0, 93: -0.06037419245715384, 94: -0.09089941256234661, 95: 0.0, 96: -0.09031145916033803, 97: -0.0605281492231964, 98: 0.0, 99: -0.10393099714318904, 100: -0.08506804256934303, 101: -0.05767492305306878, 102: -0.087643718000509, 103: -0.059705984069972136, 104: 0.0, 105: 0.0, 106: 0.0, 107: -0.11643193622140503, 108: -0.08589925040445116, 109: -0.09041466232836658, 110: -0.05928840787699679, 111: -0.10882298347012416, 112: 0.0, 113: 0.0, 114: -0.12215428393645603, 115: -0.06083843040843744, 116: 0.0, 117: 0.0, 118: -0.06500373096436965, 119: -0.09577769746172755, 120: -0.10993179228046238, 121: 0.0, 122: -0.05878913744854423, 123: -0.10744371212209447, 124: 0.0, 125: -0.09202717387052263, 126: -0.06670727243580146, 127: -0.09145981683393326, 128: -0.06006861661933132, 129: -0.061500488206317636, 130: -0.13724918048691043, 131: -0.06306925188745943, 132: -0.06182084470933862, 133: 0.0, 134: -0.14228448626471774, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: -0.061500488206317636, 142: -0.05747939131067321, 143: -0.09224175173950536, 144: 0.0, 145: 0.0, 146: 0.0, 147: -0.05946665173379024, 148: 0.0, 149: -0.05855708477900265, 150: 0.0, 151: -0.0884273436885632, 152: 0.0, 153: -0.09497292418396802, 154: 0.0, 155: -0.055988005882008446, 156: 0.0, 157: 0.0, 158: -0.06290211474358813, 159: 0.0, 160: -0.058041605260727804, 161: 0.0, 162: -0.05826958242860108, 163: 0.0, 164: 0.0})\n",
      "season 7/Friends - 7x06 - The One With The Nap Partners: 0.0\n",
      "season 7/Friends - 7x19 - The One With Ross And Monica's Cousin: 0.0\n",
      "season 7/Friends - 7x18 - The One With Joey's Award: 0.0\n",
      "season 7/Friends - 7x10 - The One With The Holiday Armadillo: 0.0\n",
      "season 7/Friends - 7x13 - The One Where Rosita Dies: 0.0\n",
      "season 7/Friends - 7x09 - The One With All The Candy: 0.0\n",
      "season 7/Friends - 7x15 - The One With Joey's New Brain: 0.0\n",
      "season 7/Friends - 7x02 - The One With Rachel's Book: 0.0\n",
      "season 7/Friends - 7x24-25 - The One With Chandler And Monica's Wedding (2): 0.0\n",
      "season 7/Friends - 7x12 - The One Where They're Up All Nigh: 0.0\n"
     ]
    }
   ],
   "source": [
    "res = search_inv_index('ходить', inverted_index, term_doc_matrix, files_length, 10)\n",
    "for elem in res:\n",
    "    print('{}: {}'.format(elem[0], elem[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./flask/model/araneum_none_fasttextskipgram_300_5_2018.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_w2v_vectors(model, lemmas):\n",
    "    \"\"\"Получает вектор документа\"\"\"\n",
    "    \n",
    "    vec_list = []\n",
    "    \n",
    "    for lemma in lemmas:\n",
    "        if lemma in model.wv:\n",
    "            vec_list.append(model.wv[lemma])\n",
    "        \n",
    "    doc_vec = sum(vec_list) / len(vec_list)\n",
    "    \n",
    "    return doc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_w2v_base(files_list, prepro_files, model):\n",
    "    \"\"\"Индексирует всю базу для поиска через word2vec\"\"\"\n",
    "    \n",
    "    doc_index = []    \n",
    "    \n",
    "    for lemmas in prepro_files:\n",
    "\n",
    "        vec = get_w2v_vectors(model, lemmas)\n",
    "            \n",
    "        file_index = {'index': files_list[prepro_files.index(lemmas)], 'vec': vec}\n",
    "        doc_index.append(file_index)\n",
    "    \n",
    "    with open('w2v_indexed_base' + '.pkl', 'wb') as fw:\n",
    "            pickle.dump(doc_index, fw)\n",
    "\n",
    "    return doc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('w2v_indexed_base.pkl', 'rb') as f:\n",
    "    w2v_base = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_base = save_w2v_base(files_list, prepro_files, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция измерения близости между векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "import numpy as np \n",
    "\n",
    "def similarity(v1, v2):\n",
    "    v1_norm = matutils.unitvec(np.array(v1))\n",
    "    v2_norm = matutils.unitvec(np.array(v2))\n",
    "    return np.dot(v1_norm, v2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция поиска по Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_w2v(query, model, w2v_base, n_results):\n",
    "    \n",
    "    query_vec = get_w2v_vectors(model, preprocessing(query))\n",
    "    \n",
    "    similarities = {}\n",
    "    \n",
    "    for doc in w2v_base:\n",
    "        sim = similarity(query_vec, doc['vec'])\n",
    "        similarities[sim] = doc['index']\n",
    "        \n",
    "    results = [re.split('/Friends - season [0-9]/Friends - ', similarities[sim].strip('.ru.txt'))[1]\n",
    "               for sim in sorted(similarities, reverse=True)[:n_results]]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(query, search_method, n_results=10):\n",
    "\n",
    "    if search_method == 'inverted_index':\n",
    "        search_result = search_inv_index(query, inverted_index, term_doc_matrix, files_length, n_results)\n",
    "\n",
    "    elif search_method == 'word2vec':\n",
    "        search_result = search_w2v(query, model, w2v_base, n_results)\n",
    "        \n",
    "    else:\n",
    "        raise TypeError('unsupported search method')\n",
    "        \n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/socur/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'ывшршыа' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-8f538e552a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ывшршыа'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 )\n\u001b[0;32m-> 1398\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \"\"\"\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'ывшршыа' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model['ывшршыа']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('season 7/Friends - 7x10 - The One With The Holiday Armadillo',\n",
       "  9.774760701134205),\n",
       " (\"season 6/Friends - 6x19 - The One With Joey's Fridge\", 7.8319086214455185),\n",
       " ('season 3/Friends - 3x10 - The One Where Rachel Quits', 5.600988808869542),\n",
       " (\"season 2/Friends - 2x09 - The One With Phoebe's Dad\", 4.78695819559373),\n",
       " ('season 1/Friends - 1x17 - The One With Two Parts (2)', 4.140265683391886),\n",
       " (\"season 4/Friends - 4x03 - The One With The 'Cuffs\", 4.120980621964985),\n",
       " ('season 1/Friends - 1x16 - The One With Two Parts (1)', 4.053326905862368),\n",
       " ('season 4/Friends - 4x10 - The One With The Girl From Poughkeepsie',\n",
       "  4.02566179468818),\n",
       " ('season 6/Friends - 6x12 - The One With The Joke', 3.4605118646078226),\n",
       " ('season 6/Friends - 6x09 - The One Where Ross Got High', 3.4152600172747283)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('рождественские каникулы', 'inverted_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7x10 - The One With The Holiday Armadillo',\n",
       " '2x22 - The One With The Two Parties',\n",
       " \"2x09 - The One With Phoebe's Dad\",\n",
       " '4x10 - The One With The Girl From Poughkeepsie',\n",
       " '1x09 - The One Where Underdog Gets Away',\n",
       " '6x10 - The One With The Routine',\n",
       " '7x11 - The One With All The Cheesecakes',\n",
       " '6x09 - The One Where Ross Got High',\n",
       " '3x10 - The One Where Rachel Quits',\n",
       " \"7x02 - The One With Rachel's Book\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('рождественские каникулы', 'word2vec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
